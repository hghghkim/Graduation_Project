{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Input\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load('/home/ckwwk/data/germination_data/train_germination.npy')\n",
    "val_x = np.load('/home/ckwwk/data/germination_data/val_germination.npy')\n",
    "test_x = np.load('/home/ckwwk/data/germination_data/test_germination.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = train_x[:,:,:,80:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 61, 61, 60, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = val_x[:,:,:,80:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 61, 61, 60, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1 = test_x[:,:,:,80:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 61, 61, 60, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  1\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "label_df = pd.read_csv(\"/home/ckwwk/data/label/germination_label.csv\")\n",
    "label_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_y = label_df[0:1000]\n",
    "train_y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = label_df[1000:1250]\n",
    "val_y = to_categorical(val_y)\n",
    "test_y = label_df[1250:1536]\n",
    "test_y = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import tensorflow_backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0809 15:48:26.039416 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0809 15:48:26.041444 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0809 15:48:26.044916 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0809 15:48:26.149493 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0809 15:48:26.157627 140073036056384 deprecation.py:506] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 53, 53, 48, 64)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((61, 61, 60,1))\n",
    "\n",
    "conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 5), activation='relu')(input_layer)\n",
    "conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(conv_layer3)\n",
    "\n",
    "print(conv_layer4._keras_shape)\n",
    "conv3d_shape = conv_layer4._keras_shape\n",
    "conv_layer4 = Reshape((conv3d_shape[1], conv3d_shape[2], conv3d_shape[3]*conv3d_shape[4]))(conv_layer4)\n",
    "conv_layer5 = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(conv_layer4)\n",
    "\n",
    "flatten_layer = Flatten()(conv_layer5)\n",
    "\n",
    "dense_layer1 = Dense(units=1024, activation='relu')(flatten_layer)\n",
    "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(units=512, activation='relu')(dense_layer1)\n",
    "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "output_layer = Dense(units=2, activation='softmax')(dense_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 61, 61, 60, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 59, 59, 56, 8)     368       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 57, 57, 52, 16)    5776      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 55, 55, 50, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 53, 53, 48, 64)    55360     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 53, 53, 3072)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 51, 51, 64)        1769536   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 166464)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              170460160 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 172,830,882\n",
      "Trainable params: 172,830,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 15:48:26.252736 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0809 15:48:26.259585 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adam = Adam(lr=0.005, decay=1e-06)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"best-model_V7_1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tb = keras.callbacks.TensorBoard(log_dir='/home/ckwwk/data/C2/tensor_log_V7_1',histogram_freq=1,)\n",
    "callbacks_list = [checkpoint,tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 15:48:38.005628 140073036056384 deprecation.py:323] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 250 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 15:48:43.687303 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/callbacks.py:848: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "W0809 15:48:43.732171 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0809 15:48:43.735176 140073036056384 deprecation_wrapper.py:119] From /home/ckwwk/.conda/envs/ck/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6685 - acc: 0.6210 - val_loss: 0.6824 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61600, saving model to best-model_V7_1.hdf5\n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.6622 - acc: 0.6320 - val_loss: 0.6658 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.61600\n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.6646 - acc: 0.6320 - val_loss: 0.7334 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61600\n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.6644 - acc: 0.6320 - val_loss: 0.6681 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61600\n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6620 - acc: 0.6320 - val_loss: 0.6668 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.61600\n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6606 - acc: 0.6320 - val_loss: 0.6677 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.61600\n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6618 - acc: 0.6320 - val_loss: 0.6658 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.61600\n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.6610 - acc: 0.6320 - val_loss: 0.6660 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.61600\n",
      "Epoch 9/1000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.6578 - acc: 0.6320 - val_loss: 0.6688 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.61600\n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6618 - acc: 0.6320 - val_loss: 0.6771 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.61600\n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6590 - acc: 0.6320 - val_loss: 0.6669 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.61600\n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.6608 - acc: 0.6320 - val_loss: 0.6661 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.61600\n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6607 - acc: 0.6320 - val_loss: 0.6663 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.61600\n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6594 - acc: 0.6320 - val_loss: 0.6717 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.61600\n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.6597 - acc: 0.6320 - val_loss: 0.6674 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61600\n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6614 - acc: 0.6320 - val_loss: 0.6661 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61600\n",
      "Epoch 17/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6590 - acc: 0.6320 - val_loss: 0.6662 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.61600\n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6590 - acc: 0.6320 - val_loss: 0.6677 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.61600\n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6590 - acc: 0.6320 - val_loss: 0.6670 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.61600\n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6601 - acc: 0.6320 - val_loss: 0.6659 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.61600\n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.6576 - acc: 0.6320 - val_loss: 0.6694 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.61600\n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6580 - acc: 0.6320 - val_loss: 0.6668 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.61600\n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.6622 - acc: 0.6320 - val_loss: 0.6660 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.61600\n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.6601 - acc: 0.6320 - val_loss: 0.6659 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.61600\n",
      "Epoch 25/1000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.6595 - acc: 0.6320 - val_loss: 0.6660 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.61600\n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.6598 - acc: 0.6320 - val_loss: 0.6671 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.61600\n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.6586 - acc: 0.6320 - val_loss: 0.6667 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.61600\n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.6578 - acc: 0.6320 - val_loss: 0.6660 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.61600\n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.6585 - acc: 0.6320 - val_loss: 0.6666 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.61600\n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.6587 - acc: 0.6320 - val_loss: 0.6659 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.61600\n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.6593 - acc: 0.6320 - val_loss: 0.6665 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.61600\n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.6597 - acc: 0.6320 - val_loss: 0.6668 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.61600\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=t1, y=train_y, batch_size=32, epochs=1000, validation_data=(v1,val_y),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best-model_V7_1.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(tt1,test_y,batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
